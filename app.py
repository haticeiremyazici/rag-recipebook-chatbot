import streamlit as st
import os
# RAG Bile≈üenleri i√ßin gerekli importlar
from chromadb import PersistentClient # <<< Dƒ∞REKT CHROMA DB
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.embeddings import HuggingFaceEmbeddings
from google.colab import userdata

# -----------------------------------------------------------
# RAG Bile≈üenlerini Tanƒ±mlama (3. A≈üamadan Tekrar Kullanƒ±m)
# -----------------------------------------------------------
try:
    GEMINI_KEY = userdata.get("GEMINI_API_KEY")
except:
    GEMINI_KEY = os.getenv("GEMINI_API_KEY") # Diƒüer deploy platformlarƒ± i√ßin

# Embedding Modelini Tanƒ±mla
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# ChromaDB'yi Y√ºkle (Dosyadan y√ºkler, tekrar vekt√∂rle≈ütirmez)
client = PersistentClient(path="./chroma_db")
vector_store_collection = client.get_collection(
    name="langchain", # LangChain'in varsayƒ±lan adƒ±dƒ±r
    embedding_function=embeddings
from langchain_community.vectorstores import Chroma
vector_store = Chroma(
    client=client,
    collection_name="langchain",
    embedding_function=embeddings
)
retriever = vector_store.as_retriever(search_kwargs={"k": 3})

# LLM Modelini Tanƒ±mla
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.2, api_key=GEMINI_KEY)

# Prompt ≈ûablonu (Chatbot'un g√∂revi)
prompt_template = """
Sen, sadece saƒülanan tariflere dayanarak cevap veren bir Yemek Tarifi Uzmanƒ±sƒ±n.
G√∂rev: Yalnƒ±zca a≈üaƒüƒ±da verilen baƒülam (tarif) i√ßinde sorulan soruya cevap ver.
Eƒüer tarif defterinde bilgi yoksa, "Bu tarif defterinde bu bilgi bulunmamaktadƒ±r." diye cevap ver.
Baƒülam (Tarif): {context}
Soru: {question}
Cevap:
"""
prompt = ChatPromptTemplate.from_template(prompt_template)

# LCEL Zincirini Kur
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# -----------------------------------------------------------
# STREAMLIT ARAY√úZ√ú
# -----------------------------------------------------------
st.title("üç∞ Tarif Defteri Asistanƒ± Chatbot (RAG)")
st.write("PDF'teki tariflere (Vi≈üneli G√ºl Tatlƒ±sƒ±, Lor Tatlƒ±sƒ± vb.) dayanarak sorularƒ±nƒ±zƒ± cevaplƒ±yorum.")

query = st.text_input("Hangi tatlƒ±nƒ±n malzemelerini veya tarifini √∂ƒürenmek istersiniz?")

if query:
    with st.spinner('Tarif defterinde arama yapƒ±lƒ±yor...'):
        response = rag_chain.invoke({"question": query})
        st.success("Tarif Cevabƒ±:")
        st.info(response)
